# Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых. \
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно. \
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой. \
Инструкция по выполнению проекта \
Загрузите и подготовьте данные. Поясните порядок действий. \
Исследуйте баланс классов, обучите модель без учёта дисбаланса. Кратко опишите выводы. \
Улучшите качество модели, учитывая дисбаланс классов. Обучите разные модели и найдите лучшую. Кратко опишите выводы. \
Проведите финальное тестирование. 

Описание данных: \
RowNumber — индекс строки в данных \
CustomerId — уникальный идентификатор клиента \
Surname — фамилия \
CreditScore — кредитный рейтинг \
Geography — страна проживания \
Gender — пол \
Age — возраст \
Tenure — сколько лет человек является клиентом банка \
Balance — баланс на счёте \
NumOfProducts — количество продуктов банка, используемых клиентом \
HasCrCard — наличие кредитной карты \
IsActiveMember — активность клиента \
EstimatedSalary — предполагаемая зарплата

Целевой признак: \
Exited — факт ухода клиента 

Выводы по исследованию: \
В первоначальные данных наблюдался значительный дисбаланс (80% ответов целевого признака были негативными и только 20% позитивными), из-за чего обученная на этих данных модель не проходила проверку на адекватность. Все модели не первоначальных данных характеризовались высокой степенью ошибок и низким качеством взвешенной величины (F1) — модели показывали низкие результаты точности и полноты. \
Мы устранили дисбаланс классов в обучающей выборки методом upsampling — увеличили количество значений позитивного класса в 4 раза. Так мы достигли баланса классо в обучеющей выборки: 0 - 0.499584 1 - 0.500416 \
Разобрались с дисбалансом классов с помощью upsample \
На новых данных все модели показали результат выше, чем на несбалансированной выборке. Лучшие показатели были у модели случайного леса: \
Полнота 0.7401869158878505 Точность 0.5462068965517242 F1-мера 0.6285714285714287 AUC-ROC 0.859615704739483 \
Финальная модель прошла проверку на адекватность и ее значения: \
Полнота 0.7707412862052038 Точность 0.5553590378493102 F1-мера 0.6455592105263157 AUC-ROC 0.8890239226821695 
